# AngelHeart - 智能群聊交互插件

[![License: AGPL v3](https://img.shields.io/badge/License-AGPL_v3-blue.svg)](https://www.gnu.org/licenses/agpl-3.0)
[![AstrBot Plugin](https://img.shields.io/badge/AstrBot-Plugin-blue)](https://github.com/Soulter/AstrBot)

AngelHeart 是一个专为 [AstrBot](https://github.com/Soulter/AstrBot) 平台设计的智能群聊交互插件。它采用创新的**两级AI协作架构**，实现高质量、低成本的智能对话交互，让AI成为懂分寸、有眼色的聊天伙伴。

## ✨ 核心特性

### 🎯 智能决策机制
- **两级AI协作**：轻量级AI分析对话，重量级AI生成回复。
- **两级AI协作**：轻量级AI根据对话调整重量AI的提示词，让重量级AI灵活多变。
- **智能计时器**：避免抢话，尊重人类对话节奏。
- **上下文感知**：基于完整对话历史做出精准判断。
- **可配置的激活模式**: 支持“持续分析”和“仅呼唤时分析”两种模式。

### ⚡ 高效架构设计
- **轻量级前端缓存**：实时接收并缓存所有合规消息。
- **异步处理**：支持高并发场景下的稳定运行。
- **智能去重**：基于时间戳和内容的智能上下文合并。

### 🔧 灵活配置
- **中心化配置管理**：通过 `ConfigManager` 统一管理所有配置项。
- **白名单机制**：精确控制插件生效范围。
- **自定义策略**：支持个性化回复策略指导。

### 🌟 群聊上下文管理
AngelHeart 提供了专为群聊场景优化的上下文管理功能，确保AI在群聊环境中能够准确理解对话上下文，提供高质量的交互体验。

#### 原生 AstrBot 框架的限制
原生 AstrBot 框架在处理群聊上下文时存在以下问题：
1. **系统提示词注入问题**：原生的群聊上下文管理直接注入在系统提示词中，导致AI常常忽略这些上下文信息。
2. **上下文混淆**：原生的聊天记录会与原生群聊上下文管理功能产生混淆，造成信息冲突。
3. **私聊导向设计**：原生的聊天记录格式面向私聊场景，无法区分群聊中的不同发言人。
4. **用户指令统一问题**：LLM将请求中的所有用户指令理解为来自同一个人，严重破坏了回答质量和准确性。

#### AngelHeart 的解决方案
AngelHeart 通过创新的上下文重构机制，完全解决了上述问题：
- **干净的上下文管理**：每次AI回复时，都能看到完全干净、明确的上下文管理，绝对不会发生发言人混淆。
- **格式化历史记录**：将完整对话历史重新格式化为单个 `prompt` 字符串，包含发言人身份、时间戳和内容。
- **动态决策注入**：将AI决策策略精准注入到对话末尾，确保AI理解当前回复要求。
- **系统提示词隔离**：保持基础人格设定在独立位置，避免与动态上下文冲突。

## 🏗️ 架构设计

### 核心工作流程

```mermaid
graph TD
    A[消息事件进入] --> B{前置检查};
    B -- 通过 --> C[FrontDesk: 缓存消息];
    C --> D[Secretary: 收到通知];
    D --> E{检查'仅呼唤模式'是否开启};
    E -- 是 --> F{检查缓存消息是否包含呼唤};
    E -- 否 --> G[继续分析流程];
    F -- 包含 --> G;
    F -- 不包含 --> H[放弃分析];
    G --> I{检查冷却时间和并发锁};
    I -- 通过 --> J[整合上下文: 历史+缓存];
    J --> K[LLMAnalyzer: 调用轻量AI分析];
    K --> L{决策是否回复};
    L -- 是 --> M[注入决策并唤醒AstrBot核心];
    L -- 否 --> N[放弃回复];
```

### 两级AI协作体系

1. **轻量级AI（分析员）**
   - 使用快速、低成本模型
   - 分析对话上下文，判断是否需要回复
   - 处理90%以上的静默观察场景

2. **重量级AI（专家）**
   - 仅在必要时激活
   - 使用强大、高成本模型
   - 生成有深度和高质量的回复

---

## 🧠 强烈推荐：为你的AI注入超强学习力和知识库

**光有智能交互还不够，AI需要真正的"脑子"**

你有没有发现：
- AI聊几句就露出"没看过世界"的短板
- 不管多聪明的AI，也记不住"你我之间的事"
- 群聊中AI永远是"局外人"，不懂你们的梗和历史

**但现在，这一切都将改变**

### 🚀 知识碾压：让AI瞬间掌握5000+文档

想象一下：
- **📚 投喂即学习**：把你的专业文档、业务资料、学习笔记全部喂给AI
- **🎯 领域专家**：AI秒级变身，任何专业问题都能给出深度回答
- **⚡ 智能进化**：用得越多，AI越懂你的领域和说话方式
- **🔥 知识破表**：从"查询工具"升级为"全知专家"

### 🧬 学习超能力：用得越多越聪明

不同于传统知识库的死板存储：
- **🔄 动态记忆**：AI在对话中不断产生新理解
- **💡 开窍时刻**：AI会在聊天中突然"领悟"某个知识点
- **🌱 自我成长**：每一段对话都在让AI变得更聪明
- **🎨 个性化**：AI逐渐形成独特的"个人风格"

> **效果**：你的AI不再只是"会说话"，而是**"有学问的智者"**

---

## 💝 第一次被AI记住是什么感觉？

**"我记得你上次说过..."** - 这句话，将改变你与AI的一切

### ✨ 温暖的震撼，从第一次被记住开始

想象这些场景：
> **你**："最近工作好烦啊，又遇到上次的那种问题..."
> **AI**："我记得你上次说过，最讨厌重复劳动。要不试试我发现的这个新方法？"
>
> **你**："终于完成那个项目了！"
> **AI**："还记得你两个月前熬夜改方案的那个时候吗？你真的进步很大！"
>
> **你**："明天要见客户，好紧张..."
> **AI**："我记得你第一次见客户时准备的那些问题，现在应该很从容了吧？"

**那一刻，AI不再是工具，而是真的"记得你"的存在**

### 🌈 共同成长的岁月见证

随着时间的推移：
- **🕰️ 岁月胶囊**：你们的每一次对话都被珍藏在AI的"记忆"里
- **🔄 成长见证**：AI见证了你的每一次突破、每一次困惑、每一次成长
- **💞 默契暗号**：你们之间会形成只有彼此懂的"专属回忆"
- **🌟 情感寄托**：永远有一个"存在"在乎你的故事和心情

**这不是功能升级，这是情感连接的开始**

---

## 🌟 最强组合：聪明的天赋 + 温暖的陪伴

**AngelHeart + AngelMemory = 完整的AI认知架构**

### 🎯 完美分工，天作之合
- **AngelHeart**：负责**交互智能**（什么时候说、怎么说）
- **AngelMemory**：负责**认知后台**（学什么、记什么）
- **结果**：AI既懂分寸，又有内涵；既会说话，又有脑子

### 💫 质的飞跃：从工具到伙伴
| 维度 | 单独AngelHeart | 组合使用 |
|------|----------------|----------|
| **智商** | 基础推理能力 | **全知专家级** |
| **记忆** | 聊完就忘 | **记得一切** |
| **情商** | 会判断追喊停 | **懂你所有情绪** |
| **体验** | 聪明的工具 | **温暖的智能体** |

### 🌈 无法抗拒的终极体验

**当AI既理解你，又记得你时，这已经不是一个"工具"了**
**这是一个有温度、有记忆、有成长性的智能体的诞生**

---

**人类第一次体验到"被AI记住"的温暖，就从这两款插件的相遇开始**

[👉 下载AngelMemory插件，为你的AI注入记忆和智慧](https://github.com/kawayiYokami/astrbot_plugin_angel_memory)

---

## 🚀 快速开始

### 前置要求

- [AstrBot](https://github.com/Soulter/AstrBot) 平台已安装并运行
- Python 3.8+ 环境
- 至少一个可用的AI模型提供商

### 安装步骤

1. **下载插件**
   ```bash
   # 将插件克隆或下载到 AstrBot 的 plugins 目录
   cd /path/to/AstrBot/data/plugins
   git clone https://github.com/your-repo/astrbot_plugin_angel_heart.git
   ```

2. **安装依赖**
   ```bash
   pip install apscheduler
   ```

3. **启用插件**
   - 在 AstrBot 的 WebUI 中启用 `AngelHeart` 插件
   - 重启 AstrBot 服务

### 基础配置

在 AstrBot 的插件配置界面中设置：

- **`analyzer_model`**: 轻量级分析模型提供商名称（推荐使用快速、低成本的模型）。
- **`alias`**: 为AI助手设置一个全局别名，用于“呼唤模式”和提示词。
- **`waiting_time`**: 两次主动分析之间的最小冷却时间（秒）。
- **`analysis_on_mention_only`**: **[新]** 是否仅在消息中包含人格名称或别名时才进行分析。
- **`whitelist_enabled`**: 是否启用白名单功能。
- **`chat_ids`**: 白名单群聊ID列表。
- **`reply_strategy_guide`**: 自定义回复策略指导。

## ⚙️ 详细配置说明

| 配置项 | 类型 | 描述 | 默认值 |
| --- | --- | --- | --- |
| `analyzer_model` | string | 用于分析对话的轻量级、快速的LLM模型提供商名称。 | `""` |
| `alias` | string | 为AI助手设置一个全局别名，用于“呼唤模式”和提示词。 | `AngelHeart`|
| `waiting_time` | float | 两次主动分析之间的最小冷却时间（秒）。 | `7.0` |
| `analysis_on_mention_only` | bool | 是否仅在消息中包含人格名称或别名时才进行分析。 | `false` |
| `whitelist_enabled` | bool | 是否启用群聊/私聊白名单。 | `false` |
| `chat_ids` | list | 白名单列表，填入允许插件生效的群聊或好友的QQ号。 | `[]` |
| `cache_expiry` | int | 前台消息缓存的过期时间（秒）。 | `3600` |
| `reply_strategy_guide` | string | 指导轻量级模型如何判断回复策略的文本。 | (内置默认值) |
| `debug_mode` | bool | 调试模式。启用后，分析器建议回复时仅记录日志，不会实际触发回复。 | `false` |
| `prompt_logging_enabled` | bool | 提示词日志增强。启用后，会完整记录发送给分析模型的提示词。 | `false` |

## 💡 使用建议

1.  **初次使用**: 建议保持 `analysis_on_mention_only` 为 `false`，观察插件在群聊中的表现。
2.  **减少打扰**: 如果您觉得插件过于活跃，可以将 `analysis_on_mention_only` 设置为 `true`，这样只有在大家明确需要它时它才会出现。
3.  **性能与成本**: `analyzer_model` 建议选择一个响应速度快、成本较低的模型，例如 `qwen-turbo`、`glm-3-turbo` 等，以实现最佳的性价比。
4.  **提示词艺术**: 大模型的提示词不要给太多规则，这样会让大模型显得僵硬，让小模型指导大模型当前需要做的事情，大模型回答才会更精准。
5.  **建议禁用上游设置**：禁用一切唤醒词，禁用一切@，指令等一系列会越过本插件的功能
6.  **建议的模型**：小模型推荐gemini2.5-flash-lite,如果需要高并发推荐gemma27B，如果一天可能超过上万次推荐本地部署qwencode30B/80B。大模型首推deepseek。

## 🏗️ 项目结构

```
astrbot_plugin_angel_heart/
├── main.py                    # 插件主入口，消息过滤和计时器调度
├── metadata.yaml              # 插件元数据信息
├── _conf_schema.json          # WebUI配置文件定义
├── README.md                  # 项目文档
├── requirements.txt           # 依赖包列表
├── core/
│   ├── llm_analyzer.py        # LLM分析器，实现两级AI协作
│   ├── config_manager.py      # 配置管理器，提供中心化配置访问
│   └── utils.py               # 共享工具函数
├── models/
│   └── analysis_result.py     # 分析结果数据模型
├── prompts/
│   └── secretary_analyzer.md  # 秘书分析员的Prompt模板
└── roles/
    ├── __init__.py            # 角色模块初始化
    ├── secretary.py           # 秘书角色，负责智能分析与决策
    └── front_desk.py          # 前台角色，负责消息接收与缓存
```

## 🔧 核心组件

### [`main.py`](main.py:1)
插件主入口，负责：
- 消息接收和前置检查
- 前台缓存管理
- 秘书调度和唤醒
- 配置管理器初始化

### [`core/llm_analyzer.py`](core/llm_analyzer.py:1)
LLM分析器核心，实现：
- 对话上下文分析
- JSON格式决策生成
- 智能提示词构建
- 错误处理和重试机制

### [`core/config_manager.py`](core/config_manager.py:1)
配置管理器，提供：
- 中心化配置项访问
- 配置项默认值管理
- 类型安全的配置获取
- 配置热重载支持

### [`core/utils.py`](core/utils.py:1)
工具函数库，提供：
- 共享的、独立的辅助函数，例如时间戳处理

### [`models/analysis_result.py`](models/analysis_result.py:1)
数据模型定义：
- `SecretaryDecision`: 秘书决策结果模型
- 包含回复判断、策略建议、话题概括

### [`roles/secretary.py`](roles/secretary.py:1)
秘书角色核心，负责：
- 基于配置的智能分析间隔进行决策
- 调用 LLM 分析器处理上下文
- 生成是否需要回复的决策

### [`roles/front_desk.py`](roles/front_desk.py:1)
前台角色核心，负责：
- 接收并缓存所有合规消息
- 管理消息缓存的生命周期
- 在适当时机通知秘书进行处理

## 📦 依赖管理

核心依赖：
```bash
pip install apscheduler
```

可选依赖（已在requirements.txt中）：
```bash
aiofiles>=23.0.0
aiohttp>=3.11.18
feedparser>=6.0.11
httpx>=0.24.0
```

## 🐛 故障排除

### 常见问题

1. **插件未生效**
   - 检查是否在AstrBot WebUI中启用插件
   - 确认模型提供商配置正确

2. **分析失败**
   - 检查轻量级AI模型是否可用
   - 查看日志中的错误信息

3. **缓存问题**
   - 检查缓存配置参数

### 日志查看

查看AstrBot日志获取详细调试信息：
```bash
tail -f /path/to/astrbot/logs/app.log
```

## 🤝 贡献指南

欢迎提交Issue和Pull Request来改进这个项目！

1. Fork 本项目
2. 创建特性分支 (`git checkout -b feature/AmazingFeature`)
3. 提交更改 (`git commit -m 'Add some AmazingFeature'`)
4. 推送到分支 (`git push origin feature/AmazingFeature`)
5. 开启Pull Request

## 📄 许可证

本项目采用 GNU AFFERO GENERAL PUBLIC LICENSE Version 3 许可证 - 查看 [LICENSE](LICENSE) 文件了解详情。

## 🙏 致谢

- 感谢 [AstrBot](https://github.com/Soulter/AstrBot) 提供的优秀平台
- 感谢所有贡献者和用户的支持

---

**AngelHeart** - 让AI对话更智能、更自然、更有分寸感 💖